{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f616a39-4fe2-4d50-973b-3110e2c1723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import GMFTrainer\n",
    "from models.base_model import GMF\n",
    "from evaluation.evaluator import Evaluator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cd2f5f-b277-482d-8954-37c2af386135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_train_df = pd.read_json('data_files/train_sessions.jsonl', lines=True)\n",
    "tracks_df = pd.read_json('data_files/tracks.jsonl', lines=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.LongTensor(sessions_train_df['user_id'].values).to(device),\n",
    "    torch.LongTensor(sessions_train_df['track_id'].values).to(device),\n",
    "    torch.FloatTensor(sessions_train_df['score'].values).to(device)\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "unique_users_count = sessions_train_df['user_id'].nunique()\n",
    "unique_tracks_count = len(tracks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cdc5f9-2dc6-40a2-8b3e-ecf8e93b7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf = GMF(unique_users_count, unique_tracks_count, 64)\n",
    "gmf_trainer = GMFTrainer(gmf, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fc7882-cf69-49e9-a234-82ca20db6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Average Loss: 0.1429\n",
      "Epoch 2/10 - Average Loss: 0.1374\n",
      "Epoch 3/10 - Average Loss: 0.1374\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgmf_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/playlist_recommendation_system/models/training.py:20\u001b[0m, in \u001b[0;36mGMFTrainer.train\u001b[0;34m(self, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_ids, item_ids, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m---> 20\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(predictions, labels)\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/playlist_recommendation_system/models/base_model.py:17\u001b[0m, in \u001b[0;36mGMF.forward\u001b[0;34m(self, user_input, item_input)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_input, item_input):\n\u001b[0;32m---> 17\u001b[0m     user_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     item_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embedding(item_input)\n\u001b[1;32m     20\u001b[0m     element_product \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(user_embedded, item_embedded)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gmf_trainer.train(10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b28b0e-e5bb-4b61-8c69-98f637d8001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_json('data_files/val_sessions.jsonl', lines=True)\n",
    "ground_truth_df = ground_truth_df[ground_truth_df['user_id'] < 1000]\n",
    "all_users = torch.arange(1000).to(device)\n",
    "all_items = torch.arange(unique_tracks_count).to(device)\n",
    "all_pairs = torch.cartesian_prod(all_users, all_items)\n",
    "user_input = all_pairs[:,0]\n",
    "item_input = all_pairs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c35eb8-45f7-43ed-a2c8-39e392fb317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "batch_size = 10000\n",
    "gmf.eval()\n",
    "for i in range(0, len(all_pairs), batch_size):\n",
    "    batch_pairs = all_pairs[i:i + batch_size]\n",
    "    batch_user_input = batch_pairs[:,0].to(device)\n",
    "    batch_item_input = batch_pairs[:,1].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_predictions = gmf.forward(batch_user_input, batch_item_input)\n",
    "        predictions.append(batch_predictions)\n",
    "\n",
    "all_predictions = torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0120ce8f-10e6-4711-9ea4-79f30443e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs_np = all_pairs.cpu().numpy()\n",
    "all_predictions_np = all_predictions.cpu().numpy()\n",
    "\n",
    "recommendations_df = pd.DataFrame({\n",
    "    'user_id': all_pairs_np[:, 0],\n",
    "    'track_id': all_pairs_np[:, 1],\n",
    "    'score': all_predictions_np\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10820d4b-fb46-4d65-b756-718a8ec1da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator2 = Evaluator([5, 10, 20, 30, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1080fb45-2897-4fe7-898b-efc87e1752f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator2.evaluate(recommendations_df, ground_truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee2e449-7e84-4b90-87bd-ac20801b02f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 99.91292107971039%\n",
      "NDCG@5_std: 0.7648140548486799%\n",
      "Recall@5: 0.013821483852649002%\n",
      "Recall@5_std: 0.13974309497832507%\n",
      "Precision@5: 0.24000000000000002%\n",
      "Precision@5_std: 2.1787948841382816%\n",
      "NDCG@10: 99.87302027922004%\n",
      "NDCG@10_std: 0.8376597539450039%\n",
      "Recall@10: 0.025048542436235558%\n",
      "Recall@10_std: 0.19274965189888474%\n",
      "Precision@10: 0.2%\n",
      "Precision@10_std: 1.4007005254378833%\n",
      "NDCG@20: 99.77673698250403%\n",
      "NDCG@20_std: 1.0113474037145722%\n",
      "Recall@20: 0.07874948654134359%\n",
      "Recall@20_std: 0.5134336692260161%\n",
      "Precision@20: 0.24000000000000002%\n",
      "Precision@20_std: 1.2222495219446372%\n",
      "NDCG@30: 99.70846496692879%\n",
      "NDCG@30_std: 1.043247938605575%\n",
      "Recall@30: 0.10852740199433146%\n",
      "Recall@30_std: 0.5496050154785117%\n",
      "Precision@30: 0.24333333333333335%\n",
      "Precision@30_std: 0.964680458060565%\n",
      "NDCG@50: 99.58641218142547%\n",
      "NDCG@50_std: 1.0834232173818297%\n",
      "Recall@50: 0.20811692031841036%\n",
      "Recall@50_std: 0.7154922025828906%\n",
      "Precision@50: 0.27999999999999997%\n",
      "Precision@50_std: 0.8162513499322781%\n"
     ]
    }
   ],
   "source": [
    "for metric, value in metrics.items():\n",
    "    print(f'{metric}: {value * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd07819-8b8c-4c27-8e99-799ec526a1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
